# app.py
import streamlit as st
import pandas as pd
from src.graph.builder import build_graph
import base64
import os
from dotenv import load_dotenv

# Carrega a GOOGLE_API_KEY do arquivo .env
load_dotenv()

# --- Configura칞칚o da P치gina ---
st.set_page_config(
    page_title="MAMA-X 풜mega | EDA Agent System",
    page_icon="游뱄",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Estilo CSS Customizado ---
st.markdown("""
<style>
    .stApp { background-color: #f0f2f6; }
    .st-emotion-cache-16txtl3 { padding: 2rem 1rem 10rem; }
    .st-chat-message { background-color: #ffffff; border-radius: 0.5rem; padding: 1rem; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
</style>
""", unsafe_allow_html=True)

# --- Inicializa칞칚o do Estado da Sess칚o ---
if 'graph' not in st.session_state:
    st.session_state.graph = build_graph()
    st.session_state.messages = []
    st.session_state.raw_df = None
    st.session_state.df_profile = None
    st.session_state.session_id = os.urandom(24).hex()

# --- Barra Lateral (Sidebar) ---
with st.sidebar:
    st.title("MAMA-X 풜mega")
    st.markdown("### Sistema de An치lise de Dados Aut칪nomo")
    st.divider()
    st.header("1. Carregar Dados")
    uploaded_file = st.file_uploader("Escolha um arquivo CSV", type="csv", label_visibility="collapsed")

    if uploaded_file:
        try:
            df = pd.read_csv(uploaded_file)
            st.session_state.raw_df = df
            st.success("Arquivo carregado!")
            with st.expander("Visualizar Amostra"):
                st.dataframe(df.head())
        except Exception as e:
            st.error(f"Erro ao carregar: {e}")
            st.session_state.raw_df = None
    
    st.divider()
    st.info("Este prot칩tipo foi constru칤do seguindo as diretrizes do MAMA-X 풜mega.")

# --- 츼rea Principal da Aplica칞칚o ---
st.header("游뱄 Assistente de An치lise Explorat칩ria de Dados")
chat_container = st.container()
with chat_container:
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            if "image" in message and message["image"]:
                st.image(base64.b64decode(message["image"]), caption="Gr치fico Gerado pela An치lise")

prompt = st.chat_input("Ex: 'Qual a correla칞칚o entre as vari치veis?'")

if prompt:
    if st.session_state.raw_df is None:
        st.warning("Por favor, carregue um arquivo CSV na barra lateral para come칞ar.")
    else:
        with chat_container:
            with st.chat_message("user"):
                st.markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.spinner("Analisando... Os agentes est칚o colaborando."):
            initial_state = {
                "user_question": prompt,
                "raw_dataframe": st.session_state.raw_df,
                "dataframe_profile": st.session_state.df_profile,
                "conversation_history": [m['content'] for m in st.session_state.messages]
            }
            config = {"configurable": {"session_id": st.session_state.session_id}}
            final_state = st.session_state.graph.invoke(initial_state, config=config)
            
            if final_state.get("dataframe_profile"):
                st.session_state.df_profile = final_state["dataframe_profile"]

            response_content = final_state.get("synthesis", "Desculpe, n칚o consegui processar sua solicita칞칚o.")
            if final_state.get("error_message"):
                response_content += f"\n\n**Ocorreu um erro:** `{final_state['error_message']}`"
            
            image_b64 = final_state.get("execution_result", {}).get("image_base64")

            with chat_container:
                with st.chat_message("assistant"):
                    st.markdown(response_content)
                    if image_b64:
                        st.image(base64.b64decode(image_b64), caption="Gr치fico Gerado pela An치lise")
            
            st.session_state.messages.append({"role": "assistant", "content": response_content, "image": image_b64})
